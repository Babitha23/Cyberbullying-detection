{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM5omT9TS4K6NxGJTbSVBV9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Babitha23/Cyberbullying-detection/blob/main/Sentence_Bert_embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import Required Libraries"
      ],
      "metadata": {
        "id": "iI4CwYs2Ju6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "ZghK2HAScW6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up GPU"
      ],
      "metadata": {
        "id": "hPxDpfiEJ0vV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9eU4wPlbxhd",
        "outputId": "c77cddb5-ee05-4999-9d5c-1b39e212a73a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "Device name: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():       \n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install SBERT"
      ],
      "metadata": {
        "id": "mlSJoWvIJ4IB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U sentence-transformers\n",
        "from sentence_transformers import SentenceTransformer"
      ],
      "metadata": {
        "id": "PXwWOEHBvOsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"processeddata (1).csv\", index_col=0, encoding = \"ISO-8859-1\")"
      ],
      "metadata": {
        "id": "ePBZMOO2cTlI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the data into sentences."
      ],
      "metadata": {
        "id": "EPEt0LLlJ9pK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for i in range(2218):\n",
        "#     data['sessiontext'] = data['sessiontext'].apply(lambda x: x.str.split('.'))\n",
        "\n",
        "# new data frame with split value columns\n",
        "data[\"sentences\"]= data[\"sessiontext\"].str.split(\".\", expand = False)\n",
        "data.sample(5)"
      ],
      "metadata": {
        "id": "3UKis0z4vhPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encode the sentences and create embeddings"
      ],
      "metadata": {
        "id": "o9tP231YKJaL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "embed = []\n",
        "for i in range(2218):\n",
        "  #Our sentences we like to encode\n",
        "  sentences = str(data.iloc[i,:]['sentences'])\n",
        "  #Sentences are encoded by calling model.encode()\n",
        "  embeddings = model.encode(sentences)\n",
        "  new = []\n",
        "  for sentence, embedding in zip(sentences, embeddings):\n",
        "    new.append(embedding)\n",
        "  embed.append(new)"
      ],
      "metadata": {
        "id": "LqM71Ap_9RFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Update the generate embeddings into new column of the dataframe"
      ],
      "metadata": {
        "id": "2Zy2ze1tKSb_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['embeddings']=embed"
      ],
      "metadata": {
        "id": "piC5fMeVCT2l"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.to_csv(\"encoded_data.csv\")"
      ],
      "metadata": {
        "id": "pTKwiY_eIZjp"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenized_text = tokenizer.tokenize(marked_text)\n",
        "# indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "# segments_ids = [0] * len(tokenized_text)\n",
        "# tokens_tensor = torch.tensor([indexed_tokens])\n",
        "# segments_tensors = torch.tensor([segments_ids])\n",
        "# with torch.no_grad():\n",
        "#   outputs = model(tokens_tensor, token_type_ids=segments_tensors)\n",
        "#   hidden_states = outputs[0]"
      ],
      "metadata": {
        "id": "9w7inYEBcVzl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}